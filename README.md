ğŸš€ FIAP - Data Engineering - Projeto Final ğŸš€

Este repositÃ³rio contÃ©m o projeto final da disciplina de Data Engineering da FIAP. O objetivo Ã© construir um pipeline de ingestÃ£o, transformaÃ§Ã£o e persistÃªncia de dados utilizando PySpark, aplicando boas prÃ¡ticas de engenharia de dados.

ğŸ’¡ Arquitetura do Pipeline

O pipeline processa os dados de pagamentos (JSON) e pedidos (CSV), realiza transformaÃ§Ãµes e persiste o resultado em formato Parquet para consumo posterior.
    

âš™ï¸ PrÃ©-requisitos

Para executar o projeto, vocÃª precisa ter instalados:

Python 3.9+

PySpark (versÃ£o compatÃ­vel com o seu ambiente Spark)

pytest para rodar os testes

InstalaÃ§Ã£o

Instale as dependÃªncias listadas no requirements.txt:
 pip install -r requirements.txt

â–¶ï¸ Como Executar o Pipeline

ConfiguraÃ§Ã£o: Revise e ajuste os paths e opÃ§Ãµes de arquivos no arquivo de configuraÃ§Ã£o: src/configs/config.json.

ExecuÃ§Ã£o: Execute o script principal para rodar o pipeline de ingestÃ£o e transformaÃ§Ã£o:
 spark-submit src/main.py

ğŸ§ª Rodando os Testes

Os testes unitÃ¡rios garantem que os mÃ©todos de leitura e escrita do data_handler.py funcionem corretamente, simulando as operaÃ§Ãµes em arquivos temporÃ¡rios.

Execute os testes com o seguinte comando: pytest -v

ğŸ‘¨â€ğŸ’» Autores

Projeto desenvolvido por:

Pedro Henrique Cozzati Camillo RM361284 

Thomaz Colalillo Navajas RM364869 

Marcela Bento do Vale RM361949 

Yasmin Martins Vasconcellos RM363354 

FIAP - Data Engineering - Projeto Final
